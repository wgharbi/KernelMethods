{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def hinge_loss(x,y):\n",
    "    return max(0, 1- x*y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cvxopt\n",
    "class SVM:\n",
    "    \n",
    "    def __init__(self, C = 1., kernel = 'rbf', gamma = None):\n",
    "        self.C = C\n",
    "        if gamma == None:\n",
    "            self.gamma = 0.01\n",
    "        else:\n",
    "            self.gamma = gamma\n",
    "        if kernel =='min':\n",
    "            self.kernel_function = lambda a,b : np.sum(np.minimum(a,b))\n",
    "        if kernel =='linear':\n",
    "            self.kernel_function = lambda a,b : np.inner(a,b)\n",
    "        \n",
    "        if kernel =='rbf':\n",
    "            self.kernel_function = lambda a,b : np.exp(- self.gamma * np.linalg.norm( a-b)**2)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        n_samples = X.shape[0]\n",
    "        n_features = X.shape[1]\n",
    "        self.classes = np.unique(y)\n",
    "        \n",
    "        self.y_train = np.array([-1 if label == self.classes[0] else 1 for label in y])\n",
    "        self.X_train = X\n",
    "        y= self.y_train\n",
    "        if (X.shape[0] != y.shape[0]):\n",
    "            print \"X and y don't have the same size :\",X.shape, y.shape\n",
    "        \n",
    "        #compute the kernel matrix\n",
    "        K = np.array([np.array([self.kernel_function(x,x2) for x2 in X])for x in X])\n",
    "        self.K = K\n",
    "        # Solves\n",
    "        # min 1/2 x^T P x + q^T x\n",
    "        # s.t.\n",
    "        #  Gx \\coneleq h\n",
    "        #  Ax = b\n",
    "        P = cvxopt.matrix(np.outer(y, y) * K)\n",
    "        q = cvxopt.matrix(-1 * np.ones(n_samples))\n",
    "\n",
    "        # -a_i \\leq 0\n",
    "        # TODO(tulloch) - modify G, h so that we have a soft-margin classifier\n",
    "        G_std = cvxopt.matrix(np.diag(np.ones(n_samples) * -1))\n",
    "        h_std = cvxopt.matrix(np.zeros(n_samples))\n",
    "\n",
    "        # a_i \\leq c\n",
    "        G_slack = cvxopt.matrix(np.diag(np.ones(n_samples)))\n",
    "        h_slack = cvxopt.matrix(np.ones(n_samples) * self.C)\n",
    "\n",
    "        G = cvxopt.matrix(np.vstack((G_std, G_slack)))\n",
    "        h = cvxopt.matrix(np.vstack((h_std, h_slack)))\n",
    "        \n",
    "        \n",
    "        A = cvxopt.matrix(y, (1, n_samples),'d')\n",
    "        b = cvxopt.matrix(0.0)\n",
    "\n",
    "        solution = cvxopt.solvers.qp(P, q, G, h, A, b)\n",
    "        self.alpha = solution['x']\n",
    "        self.b = np.mean([y[j] - np.sum([self.alpha[i]*y[i] * K[i,j] for i in range(n_samples)])\n",
    "                         for j in range(n_samples)]).mean()\n",
    "        return self\n",
    "        \n",
    "            \n",
    "    def predict(self, X):\n",
    "        prediction = []\n",
    "        K_test = np.array([np.array([self.kernel_function(x,x2) for x2 in X])for x in self.X_train])\n",
    "        for i,x in enumerate(X):\n",
    "            result = self.b\n",
    "            for j in range(self.X_train.shape[0]):\n",
    "                result+= self.alpha[j]*self.y_train[j]*K_test[j,i]\n",
    "            if(np.sign(result) <0):\n",
    "                prediction.append(self.classes[0])\n",
    "            else:\n",
    "                prediction.append(self.classes[1])\n",
    "                \n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from svm import SVM\n",
    "class multiclass_svm(object):\n",
    "    def __init__(self, kernel = \"rbf\", C =1.):\n",
    "        self.kernel = kernel\n",
    "        self.C = C\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.classes = np.unique(y)\n",
    "        self.trained_classifiers = [\n",
    "            [SVM(C = self.C, kernel = self.kernel).fit(X[(y==label) | (y== label2)], y[(y==label)|(y== label2)])\n",
    "                                                if label2>label else 0\n",
    "                                                for label2 in self.classes] \n",
    "                                                for label in self.classes ]\n",
    "        return self\n",
    "        \n",
    "    def predict(self, X):\n",
    "        win_count = np.zeros((X.shape[0],len(self.classes)))\n",
    "        for i, label1 in enumerate(self.classes):\n",
    "            for j, label2 in enumerate(self.classes):\n",
    "                if label2>label1:\n",
    "                    y_test = self.trained_classifiers[i][j].predict(X)\n",
    "                    for k, winner in enumerate(y_test):\n",
    "                        if winner == label1:\n",
    "                            win_count[k,i]+=1\n",
    "                        else:\n",
    "                            win_count[k,j]+=1\n",
    "                            \n",
    "        return [self.classes[np.argmax(row)] for row in win_count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "path=\"\"\n",
    "X_train =pd.read_csv(path+\"Xtr.csv\", header=None)\n",
    "Y =pd.read_csv(path+\"Ytr.csv\")\n",
    "X_test =pd.read_csv(path+\"Xte.csv\", header=None)\n",
    "\n",
    "y_train = Y[\"Prediction\"].values\n",
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "\n",
    "from sklearn.decomposition import KernelPCA\n",
    "kpca = KernelPCA(kernel = 'rbf', degree = 3, n_components= 35, gamma= 0.01)\n",
    "\n",
    "X_train_kpca = kpca.fit_transform(X_train)\n",
    "X_test_kpca = kpca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def min_kernel(a, b):\n",
    "    return np.sum(np.minimum(a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svm = multiclass_svm(kernel='rbf',C= 10.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.1514e+03 -3.3504e+04  4e+04  7e-14  5e-14\n",
      " 1:  5.6020e+02 -4.2956e+03  5e+03  5e-14  4e-14\n",
      " 2: -3.0726e+02 -1.9818e+03  2e+03  2e-14  3e-14\n",
      " 3: -4.9613e+02 -1.5693e+03  1e+03  6e-15  3e-14\n",
      " 4: -6.0538e+02 -1.3419e+03  7e+02  4e-15  3e-14\n",
      " 5: -6.7353e+02 -1.2115e+03  5e+02  4e-14  3e-14\n",
      " 6: -7.3675e+02 -1.0924e+03  4e+02  5e-15  3e-14\n",
      " 7: -7.7890e+02 -1.0148e+03  2e+02  2e-15  4e-14\n",
      " 8: -8.0835e+02 -9.6547e+02  2e+02  5e-14  4e-14\n",
      " 9: -8.2800e+02 -9.3117e+02  1e+02  2e-14  4e-14\n",
      "10: -8.4303e+02 -9.0733e+02  6e+01  3e-14  4e-14\n",
      "11: -8.5936e+02 -8.8120e+02  2e+01  1e-14  5e-14\n",
      "12: -8.6474e+02 -8.7279e+02  8e+00  4e-14  6e-14\n",
      "13: -8.6777e+02 -8.6944e+02  2e+00  1e-14  5e-14\n",
      "14: -8.6842e+02 -8.6873e+02  3e-01  1e-14  5e-14\n",
      "15: -8.6857e+02 -8.6857e+02  6e-03  4e-14  6e-14\n",
      "16: -8.6857e+02 -8.6857e+02  6e-05  3e-14  6e-14\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.1304e+03 -3.1159e+04  3e+04  1e-13  9e-14\n",
      " 1: -9.5709e+02 -5.6376e+03  5e+03  1e-13  8e-14\n",
      " 2: -1.8822e+03 -3.5593e+03  2e+03  1e-13  9e-14\n",
      " 3: -2.2093e+03 -3.0896e+03  9e+02  5e-14  9e-14\n",
      " 4: -2.3674e+03 -2.8424e+03  5e+02  7e-14  9e-14\n",
      " 5: -2.4573e+03 -2.7163e+03  3e+02  1e-13  9e-14\n",
      " 6: -2.5207e+03 -2.6287e+03  1e+02  1e-13  1e-13\n",
      " 7: -2.5513e+03 -2.5886e+03  4e+01  7e-14  1e-13\n",
      " 8: -2.5637e+03 -2.5727e+03  9e+00  3e-14  1e-13\n",
      " 9: -2.5672e+03 -2.5683e+03  1e+00  1e-13  1e-13\n",
      "10: -2.5676e+03 -2.5678e+03  1e-01  5e-14  1e-13\n",
      "11: -2.5677e+03 -2.5677e+03  3e-03  3e-13  1e-13\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.4351e+03 -3.2061e+04  3e+04  3e-14  9e-14\n",
      " 1: -6.9831e+02 -5.1428e+03  4e+03  9e-14  7e-14\n",
      " 2: -1.4582e+03 -3.3252e+03  2e+03  5e-14  7e-14\n",
      " 3: -1.7657e+03 -2.7724e+03  1e+03  4e-14  7e-14\n",
      " 4: -1.9438e+03 -2.5009e+03  6e+02  5e-14  7e-14\n",
      " 5: -2.0278e+03 -2.3824e+03  4e+02  2e-14  7e-14\n",
      " 6: -2.1029e+03 -2.2747e+03  2e+02  9e-14  7e-14\n",
      " 7: -2.1432e+03 -2.2200e+03  8e+01  8e-14  7e-14\n",
      " 8: -2.1669e+03 -2.1889e+03  2e+01  9e-14  8e-14\n",
      " 9: -2.1749e+03 -2.1787e+03  4e+00  3e-14  9e-14\n",
      "10: -2.1764e+03 -2.1768e+03  5e-01  1e-14  8e-14\n",
      "11: -2.1766e+03 -2.1766e+03  3e-02  9e-14  9e-14\n",
      "12: -2.1766e+03 -2.1766e+03  2e-03  5e-14  8e-14"
     ]
    }
   ],
   "source": [
    "#svm = SVC(C = 10.)\n",
    "svm.fit(X_train_kpca,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fini\n",
      "coucou\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "predicted_label = svm.predict(X_test_kpca[0:100])\n",
    "#print(\"SVM - Score on train_data : \", accuracy_score(y_train, svm.predict(X_train_kpca)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 9,\n",
       " 0,\n",
       " 6,\n",
       " 9,\n",
       " 0,\n",
       " 1,\n",
       " 5,\n",
       " 9,\n",
       " 7,\n",
       " 2,\n",
       " 4,\n",
       " 9,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 4,\n",
       " 0,\n",
       " 7,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 7,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 6,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 9,\n",
       " 5,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 7,\n",
       " 0,\n",
       " 2,\n",
       " 8,\n",
       " 1,\n",
       " 7,\n",
       " 3,\n",
       " 7,\n",
       " 9,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 2,\n",
       " 7,\n",
       " 8,\n",
       " 4,\n",
       " 7,\n",
       " 3,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 8,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 8,\n",
       " 6,\n",
       " 9]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_label"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
